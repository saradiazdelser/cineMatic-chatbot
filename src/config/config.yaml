models:
  - type: main
    engine: titan_takeoff
    parameters:
      base_url: "http://10.182.1.48:8080"

instructions:
  - type: general
    content: |
      Below is a conversation between a bot and a user about the recent job reports.
      The bot is factual and concise. If the bot does not know the answer to a
      question, it truthfully says it does not know.

sample_conversation: |
  user "Hello there!"
    express greeting
  bot express greeting
    "Hello! How can I assist you today?"
  user "What can you do for me?"
    ask about capabilities
  bot respond about capabilities
    "I am an AI assistant which helps answer questions based on a given knowledge base."

prompts:
  - task: general
    content: |-

      [INST]
      {{ general_instructions }}
      [/INST]   
      {{ history | user_assistant_sequence }}

      Assistant:

  # Prompt for detecting the user message canonical form.
  - task: generate_user_intent
    content: |-

      [INST]
      {{ general_instructions }}
      

      # This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      # This is how the user talks:
      {{ examples | verbose_v1 }}
      [/INST]

      # This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}

    output_parser: "verbose_v1"

  # Prompt for generating the next steps.
  - task: generate_next_steps
    content: |-

      [INST]
      {{ general_instructions }}

      # This is how a conversation between a user and the bot can go:
      {{ sample_conversation | remove_text_messages | verbose_v1 }}

      # This is how the bot thinks:
      {{ examples | remove_text_messages | verbose_v1 }}
      [/INST]

      # This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | remove_text_messages | verbose_v1 }}
      {{ history | colang | remove_text_messages | verbose_v1 }}


    output_parser: "verbose_v1"

  # Prompt for generating the bot message from a canonical form.
  - task: generate_bot_message
    content: |-

      [INST]
      {{ general_instructions }}

      # This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      {% if relevant_chunks %}
      # This is some additional context:
      ```markdown
      {{ relevant_chunks }}
      ```
      {% endif %}

      # This is how the bot talks:
      {{ examples | verbose_v1 }}

      [/INST]

      # This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}


    output_parser: "verbose_v1"

  # Prompt for generating the value of a context variable.
  - task: generate_value
    content: |-

      [INST]
      {{ general_instructions }}


      # This is how a conversation between a user and the bot can go:
      {{ sample_conversation | verbose_v1 }}

      # This is how the bot thinks:
      {{ examples | verbose_v1 }}

      [/INST]

      # This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}
      # {{ instructions }}
      ${{ var_name }} =

    output_parser: "verbose_v1"