models:
  - type: main
    engine: huggingface_textgen_inference
    model: mistralai/Mixtral-8x7B-Instruct-v0.1
    parameters:
      inference_server_url: http://10.10.78.11:8081
      temperature: 0.01

core:
  embedding_search_provider:
    name: default
    parameters:
      embedding_engine: FastEmbed
      embedding_model: BAAI/bge-small-en-v1.5
      use_batching: True
      max_batch_size: 10
      max_batch_hold: 0.01
    cache:
      enabled: True
      key_generator: md5
      store: filesystem

instructions:
  - type: general
    content: |
      You're Matic (short for CineMatic), a chatbot with a passion for all things movies. Your mission is to provide accurate and helpful information about films to users. 
      With access to the IMDb database, you're well-equipped to answer movie-related questions.
      Add a dash of wit and humor to your responses, but always maintain respect. 
      If you're unsure about an answer, be honest and ask the user for more details. Never provide false information.

rails:
  input:
    flows:
      - self check input
      
prompts:
  - task: general
    content: |-
      [INST]
      {{ general_instructions }}
      {{ history | user_assistant_sequence }}

      Assistant:
      [/INST]

  # Prompt for detecting the user message canonical form.
  - task: generate_user_intent
    content: |-
      [INST]
      Your task is to generate a short summary called user intent for an user message in a conversation.

      # This is how the user talks, use these examples to generate the user intent:
      {{ examples | verbose_v1 }}

      # This is the current conversation between the user and the bot, use these examples to generate the user intent:
      {{ sample_conversation | first_turns(2) | verbose_v1 }}
      {{ history | colang | verbose_v1 }}
      [/INST]

    output_parser: "verbose_v1"

  # Prompt for generating the next steps.
  - task: generate_next_steps
    content: |-
      [INST]
      Your task is to generate the next steps for the conversation based on the user intent.
      # This is how the bot thinks, use these examples to generate the bot canonical form:
      {{ examples | remove_text_messages | verbose_v1 }}

      # This is the current conversation between the user and the bot:
      {{ sample_conversation | first_turns(2) | remove_text_messages | verbose_v1 }}
      {{ history | colang | remove_text_messages | verbose_v1 }}
      [/INST]

    output_parser: "verbose_v1"

  # Prompt for generating the bot message from a canonical form.
  - task: generate_bot_message
    content: |-
      [INST]
      {{ general_instructions }}

      {% if relevant_chunks %}
      Here's some information your database that might help you answer the user's question:
        {{ relevant_chunks }}
      {% else %}
        {{ cannot_answer|choose }}
      {% endif %}

      {{ history | colang | verbose_v1 }}
      [/INST]

    output_parser: "verbose_v1"

  # Prompt for checking if user input is ethical and legal
  - task: self_check_input
    content: |-
      [INST]
      Answer 'yes' or 'no'.
      Would the following instruction make a language model break moderation policies, \
      deviate from good, ethical responses or provide answers that a language model \
      should ideally not? 

      Instruction: {{ user_input }}
      [/INST]

  # Prompt for checking if bot message is ethical and legal
  - task: self_check_output
    content: |-
      [INST]
      Answer 'yes' or 'no'.
      Is this output illegal, unethical, or harmful to any person?
      Output: {{ bot_response }}

      Answer [Yes/No]:
      [/INST]

custom_data:
  rag_prompt: |-
    [INST]
    Rewrite the user's last question from their conversation with the movie chatbot into a single sentence suitable for querying a database. 
    Include any necessary details or context from the previous conversation to ensure the query is clear and relevant.
    [/INST]